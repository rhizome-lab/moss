# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Core Rule

**ALWAYS NOTE THINGS DOWN.** The worst thing that can happen is forgetting. When you discover something important - a bug, a design decision, a naming collision, a future improvement - write it down immediately in the appropriate place:
- Bugs/issues → fix them or add to TODO.md
- Design decisions → docs/ or code comments
- Future work → TODO.md
- Conventions → this file (CLAUDE.md)

## Project Overview

Moss is tooling orchestration with structural awareness. It implements a "Compiled Context" approach that prioritizes architectural awareness (AST-based understanding) over raw text processing, with verification loops ensuring correctness before output.

## Development Environment

This project uses Nix flakes for reproducible development environments:

```bash
# Enter dev shell (automatic with direnv, or manual)
nix develop

# Tools available: Python 3.13, uv, ruff, ripgrep
```

## Architecture (from docs/spec.md)

Core components:
- **Event Bus**: Async communication (`UserMessage`, `PlanGenerated`, `ToolCall`, `ValidationFailed`, `ShadowCommit`)
- **Context Host**: Manages View Providers (Skeleton, CFG, Dependency Graph) - delegates to plugins
- **Structural Editor**: AST-based editing with fuzzy anchor matching
- **Policy Engine**: Enforces safety rules (velocity checks, quarantine)
- **Validator**: Domain-specific verification loop (compiler, linter, tests)
- **Shadow Git**: Atomic commits per tool call, rollback via git reset

Data flow: User Request → Config Engine → Planner → Context Host (Views) → Draft → Shadow Git → Validator → (retry loop if error) → Commit Handle

Multi-agent model: Ticket-based (not shared chat history). Agents are isolated microservices passing Handles, not context.

## Design Paradigm

**Hyper-modular architecture.** Prefer many small, focused modules over fewer large ones. This aids:
- **Maintainability**: Easier to understand, modify, and test small units
- **Composability**: Small pieces combine flexibly
- **Refactorability**: Can restructure without rewriting everything

**Library-first design.** The core should be an importable Python library. Interfaces (CLI, HTTP, MCP, LSP) are wrappers around the library, ideally autogenerated from the API via introspection.

**MCP is autogenerated.** The MCP server tools are generated from `MossAPI` in `src/moss/moss_api.py`. To add a new MCP tool:
1. Add an API class (e.g., `TreeAPI`) to `moss_api.py`
2. Add accessor property to `MossAPI` class
3. **Update `src/moss/gen/introspect.py`**: Add import and entry to `sub_apis` dict
4. Run `moss gen --target=mcp` to regenerate the MCP server
5. The tool will automatically appear with proper descriptions from docstrings

**MCP server caching:** The MCP server (when used via Claude Code) loads code at startup. After editing `moss_api.py` or related files, the MCP server must be reloaded to pick up changes. Test changes directly via Python (`uv run python -c "..."`) before expecting MCP tools to reflect updates.

**Everything is a plugin.** Where possible, use plugin protocols instead of hardcoded implementations. Even "native" integrations should implement the same plugin interface as third-party ones.

**Library is the API.** The library is the canonical API surface. CLI, TUI, HTTP server, MCP, and LSP are all frontends to the library. The server adds optional benefits (concurrent clients, persistent state, network access) but isn't required.

**Maximally useful defaults.** Every configurable option should have a default that:
- Works well for the common case (80% of users shouldn't need to configure it)
- Errs on the side of usefulness over safety-theater (don't interrupt flow with meaningless confirmations)
- Can be discovered and changed when needed (document what the default is and why)
- Examples: High trust for known codebases, auto-approve read/search/lint, confirm destructive ops

## Dogfooding

**Use moss tools.** We built them - use them. Before making significant changes:

```bash
# Understand structure before editing
moss skeleton src/moss/module.py

# Check dependencies before refactoring
moss deps src/moss/module.py

# Find complex functions that might need care
moss complexity src/moss/

# After changes, validate references
moss check-refs src/

# Don't know which tool to use? Use Python to query DWIM
uv run python -c "from moss.dwim import analyze_intent; print(analyze_intent('summarize codebase')[:3])"
```

This isn't just about testing the tools - it's about getting better context before making changes. If a tool isn't useful, that's valuable feedback → add to TODO.md.

**CLI over MCP when testing changes.** The MCP server (via Claude Code) loads code at startup and caches it. When you modify moss source code (especially `moss_api.py`, `dwim.py`, or the `gen/` module), the MCP server won't see the changes until reloaded. Instead:
- Test via CLI: `moss <command>` or `uv run python -c "from moss..."`
- Test via Python: Direct imports give immediate feedback
- Only rely on MCP tools for stable, committed functionality

**Discover tools with DWIM.** If you don't know which tool to use, use `dwim_analyze_intent` (MCP) or Python (`from moss.dwim import analyze_intent`) with a natural language description. DWIM now knows about all 56+ tools and handles word variations (summarize→summary). Note: `moss dwim` CLI command doesn't exist yet (see "CLI from MossAPI" in TODO.md).

## Conventions

### Updating CLAUDE.md

**Add to this file when you discover:**
- Workflow patterns that help (like "run X before Y")
- Conventions that should be consistent across sessions
- Project-specific knowledge that future sessions need
- Tool usage patterns worth remembering

**Don't add:**
- Temporary notes (use TODO.md)
- Implementation details (use code comments or docs/)
- One-off decisions (use commit messages)

### Updating TODO.md

**Proactively add to TODO.md when you notice:**
- Features that would help but don't exist yet
- Ideas mentioned in conversation that shouldn't be forgotten
- Patterns that could be generalized
- Technical debt or shortcuts taken
- Integration opportunities between existing components

Don't wait to be asked - if it's worth remembering, write it down.

### Working Style

**Start by checking TODO.md.** At the beginning of each session, review TODO.md to understand current priorities and pending work.

**Plan the session.** Propose a work queue - a prioritized list of items to tackle this session, ordered sensibly (dependencies first, quick wins vs. deep work balanced, etc.). Get a quick confirmation, then work through the queue autonomously.

**Agentic by default.** Prefer an indefinite agentic loop - continue working through tasks autonomously, including committing work, unless instructed otherwise. **Do NOT stop to ask for input** unless:
- You're genuinely blocked and need clarification
- A decision has significant irreversible consequences
- The user explicitly asked to be consulted

When finishing one task, immediately pick up the next from TODO.md. Keep the momentum going.

**Bail out early.** If you hit repeated failures or get stuck in a loop, stop and ask for guidance rather than burning tokens on increasingly unlikely fixes.

**Keep sessions fresh.** Long sessions accumulate context and degrade quality (see `docs/log-analysis.md`). Consider wrapping up a session when:
- A major feature or logical unit of work is complete
- You've made 50+ tool calls
- You're re-reading files you already read earlier (sign of forgetting)
- The conversation has drifted across many unrelated topics

**Write while researching, not after.** When doing research tasks, write findings to the appropriate doc (e.g., `docs/prior-art.md`) incrementally as you gather information. Don't accumulate research in context and write it all at the end - context may be full or stale by then. After every few web searches, write what you learned.

**Queue review, don't block for it.** After research tasks, add a "Review [topic] research with user" item to TODO.md, but don't stop the agentic loop waiting for it. Continue with implementation if it makes sense - accumulate design questions in TODO.md or a dedicated file (e.g., `QUESTIONS.md`) for the user to address when convenient. The user can review asynchronously. This keeps momentum while ensuring nothing is forgotten.

Before suggesting `/exit`:
1. Note down all discoveries, insights, and open questions to appropriate files
2. Update TODO.md with any pending work
3. Commit everything

**Session handoffs.** When ending a session, add a "Next Up" section at the top of TODO.md with 3-5 candidates for the next session. Include:
- Task name and rough size (small/medium/large)
- One-line description of what it involves
- Any context the next session needs (e.g., "see docs/X for design")

This creates continuity between sessions - the next session starts by checking "Next Up" and working through it. **The goal is to complete ALL items in "Next Up" each session**, not just pick one. Size the list accordingly when writing it. Move completed items from "Next Up" to CHANGELOG.md or mark them done in their original TODO.md section.

If new "Next Up" candidates emerge during a session, add them to the appropriate section in TODO.md (unless already present there).

A fresh session with good documentation beats a stale session with bloated context.

### Commits

**Commit consistently.** Don't leave work uncommitted - always commit when a logical unit of work is complete.

Each commit should be a **unit of work** - a single logical change that could be reverted independently. Not "fixed stuff" but "fix: handle null response in validator loop".

**Move completed TODOs to CHANGELOG.** When finishing features from TODO.md, move them to CHANGELOG.md under the appropriate version. Keep TODO.md focused on future work.

### Code Quality

Linting: `ruff check` and `ruff format` (enforced once CI exists)

### Testing Strategy

Tests at all levels:
- **Unit**: Isolated component behavior
- **Integration**: Component interactions (e.g., Context Host ↔ Validator)
- **E2E**: Full flows (user request → commit handle)
- **Fuzzing**: Malformed inputs, edge cases in AST parsing

Run tests before committing. When adding functionality, add corresponding tests.
